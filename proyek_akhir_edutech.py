# -*- coding: utf-8 -*-
"""Proyek Akhir: Edutech

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AJsGP1N5equE22Z_I8eMDiZMWdzk-YNp

# Proyek Akhir : Menyelesaikan Permasalahan Perusahaan Edutech

### Nama: Muhammad Rivaldi
### Email: rivalsbr@gmail.com
### Id Dicoding:rivalsbr

## Persiapan

### Menyiapkan library yang dibutuhkan
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import sklearn
import joblib

from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, roc_curve, roc_auc_score, classification_report, f1_score
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import GridSearchCV

"""### Menyiapkan data yang akan digunakan"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd

student_df = pd.read_csv('/content/drive/MyDrive/ColabNotebooks/student.csv', sep=";")

"""## Data Understanding

menampilkan sekilas data frame
"""

student_df.head()

"""menampilkan tipe data"""

student_df.info()

"""menampilkan statistik deskriptif"""

student_df.describe()

"""menampilkan missing value"""

student_df.isna().sum()

"""menampilkan data duplikat"""

student_df.duplicated().sum()

"""## Data Preparation / Preprocessing

menampilkan nilai unik pada kolom status
"""

student_df['Status'].value_counts()

"""menghapus kategori enrolled pada kolom status"""

student_df = student_df[student_df.Status!='Enrolled']

"""menampilkan distribusi status"""

sns.countplot(x='Status', data=student_df)
plt.title('Distribusi Status')
plt.show()

"""mengubah nilai pada kolom status menjadi numerik"""

student_df['Status']=student_df['Status'].map({'Dropout':0,
                                                 'Graduate':1
})

"""menampilkan korelasi antar variabel"""

plt.figure(figsize=(30, 30))
sns.heatmap(student_df.corr() , annot=True, cmap='coolwarm', linewidths=0.5)
plt.title('Correlation Heatmap')
plt.show()

student_df.corr()['Status']

"""menghapus kolom dengan korelasi kecil terhadap kolom status"""

student_df.drop(columns=['Marital_status',
                          'Age_at_enrollment',
                          'Application_mode',
                          'Application_order',
                          'Course',
                          'Previous_qualification',
                          'Nacionality',
                          'Mothers_qualification',
                          'Fathers_qualification',
                          'Mothers_occupation',
                          'Fathers_occupation',
                          'Educational_special_needs',
                          'International',
                          'Curricular_units_1st_sem_evaluations',
                          'Curricular_units_1st_sem_without_evaluations',
                          'Curricular_units_2nd_sem_evaluations',
                          'Curricular_units_2nd_sem_without_evaluations',
                          'Unemployment_rate',
                          'Inflation_rate',
                          'GDP'], axis=1, inplace=True)
student_df.info()

"""mengubah variabel dengan tipe numerik menjadi string"""

student_df['Gender'] = student_df['Gender'].astype(str).replace({'0': 'Male', '1': 'Female'})
student_df['Displaced'] = student_df['Displaced'].astype(str).replace({'0': 'No', '1': 'Yes'})
student_df['Debtor'] = student_df['Debtor'].astype(str).replace({'0': 'No', '1': 'Yes'})
student_df['Scholarship_holder'] = student_df['Scholarship_holder'].astype(str).replace({'0': 'No', '1': 'Yes'})
student_df['Tuition_fees_up_to_date'] = student_df['Tuition_fees_up_to_date'].astype(str).replace({'0': 'No', '1': 'Yes'})
student_df['Daytime_evening_attendance'] = student_df['Daytime_evening_attendance'].astype(str).replace({'0': 'Evening', '1': 'Daytime'})
student_df['Status'] = student_df['Status'].astype(str).replace({'0': 'Dropout', '1': 'Graduate'})

# Simpan file CSV
student_df.to_csv('student_fix.csv', index=False)

# Download file CSV ke lokal
from google.colab import files
files.download('student_fix.csv')

"""## Modeling

filter variabel kategori
"""

category_cols = student_df.select_dtypes(exclude=['int32','int64','float32','float64'])
category_cols.head()

"""buat direktori model dan melakukan label serta scaling"""

import os

# Check if the directory already exists
if not os.path.exists("model"):
    os.makedirs("model")
else:
    print("Directory 'model' already exists.")

def save_encoders(features, encoder):
    for feature in features:
        joblib.dump(encoder, "model/encoder_{}.joblib".format(feature))

features_to_encode = ['Daytime_evening_attendance',
                     'Displaced',
                     'Debtor',
                     'Tuition_fees_up_to_date',
                     'Gender',
                     'Scholarship_holder']

label_encoder = LabelEncoder()

# Label encode columns and save encoders
for column in features_to_encode:
    student_df[column] = label_encoder.fit_transform(student_df[column])

save_encoders(features_to_encode, label_encoder)

def save_scalers(features, scaler):
    for feature in features:
        joblib.dump(scaler, "model/scaler_{}.joblib".format(feature))

features_to_scale = ['Admission_grade',
                     'Previous_qualification_grade',
                     'Curricular_units_1st_sem_approved',
                     'Curricular_units_1st_sem_grade',
                     'Curricular_units_1st_sem_enrolled',
                     'Curricular_units_1st_sem_credited',
                     'Curricular_units_2nd_sem_approved',
                     'Curricular_units_2nd_sem_grade',
                     'Curricular_units_2nd_sem_enrolled',
                     'Curricular_units_2nd_sem_credited']

scaler = StandardScaler()

# Fit scaler to columns and save scalers
for column in features_to_scale:
    scaled_feature = scaler.fit_transform(student_df[[column]])
    scaled_feature = scaled_feature.reshape(-1, 1)  # Reshape the scaled feature
    student_df[column] = scaled_feature
    save_scalers([column], scaler)

X=np.array(student_df.drop(['Status'],axis=1))
y=np.array(student_df['Status'])

X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)
print(X_train.shape)
print(X_test.shape)

encoder = LabelEncoder()
encoder.fit(y_train)
y_train = encoder.transform(y_train)
joblib.dump(encoder, "model/encoder_target.joblib")

y_test = encoder.transform(y_test)

"""### Logistic Regression"""

# Initialize the Logistic Regression classifier
clf_lr = LogisticRegression()

# Define the grid of hyperparameters
param_grid1 = {
    'C' :[0.1, 1, 10, 100],
    'max_iter': [100, 150, 250, 400],
    'solver': ['lbfgs', 'liblinear', 'newton-cg', 'sag', 'saga'],
    'tol': [1e-4, 1e-5, 1e-6]
}

# Initialize GridSearchCV
gs1 = GridSearchCV(
    estimator=clf_lr,
    param_grid=param_grid1,
    cv=5,
    n_jobs=-1,
    scoring='accuracy'
)

# Train the classifier using GridSearchCV
clf_lr_grid = gs1.fit(X_train, y_train)

# Make predictions on the test set
y_pred = clf_lr_grid.predict(X_test)

# Print the best parameters found by GridSearchCV
print("Best parameters:", clf_lr_grid.best_params_)

# Calculate and print the test accuracy
test_accuracy = accuracy_score(y_test, y_pred)
print("The test accuracy score of Logistic Regression is", test_accuracy)

"""### Decision Tree"""

# Initialize the Decision Tree classifier
clf_dt = DecisionTreeClassifier()

# Define the grid of hyperparameters
param_grid1 = {
    'min_samples_leaf': [1, 10, 100],
    'max_depth': [1, 10, 20, 30],
    'criterion': ['gini', 'entropy']
}

# Initialize GridSearchCV
gs1 = GridSearchCV(
    estimator=clf_dt,
    param_grid=param_grid1,
    cv=5,
    n_jobs=-1,
    scoring='accuracy'
)

# Train the classifier using GridSearchCV
clf_dt_grid = gs1.fit(X_train, y_train)

# Make predictions on the test set
y_pred = clf_dt_grid.predict(X_test)

# Print the best parameters found by GridSearchCV
print("Best parameters:", clf_dt_grid.best_params_)

# Calculate and print the test accuracy
test_accuracy = accuracy_score(y_test, y_pred)
print("The test accuracy score of Decision Tree Classifier is", test_accuracy)

"""### Random Forest"""

# Initialize the Random Forest classifier
clf_rf = RandomForestClassifier()

# Define the grid of hyperparameters
param_grid1 = {
    'n_estimators': [100, 200, 300, 400],
    'max_depth': [3, 5, 7, 9],
    'criterion': ['gini', 'entropy']
}

# Initialize GridSearchCV
gs1 = GridSearchCV(
    estimator=clf_rf,
    param_grid=param_grid1,
    cv=5,
    n_jobs=-1,
    scoring='accuracy'
)

# Train the classifier using GridSearchCV
clf_rf_grid = gs1.fit(X_train, y_train)

# Make predictions on the test set
y_pred = clf_rf_grid.predict(X_test)

# Print the best parameters found by GridSearchCV
print("Best parameters:", clf_rf_grid.best_params_)

# Calculate and print the test accuracy
test_accuracy = accuracy_score(y_test, y_pred)
print("The test accuracy score of Random Forest Classifier is", test_accuracy)

"""## Evaluation

### Logistic Regression
"""

lr_cm = confusion_matrix(y_test, y_pred)
print("Confusion Matrix of Logistric Regression:")
print(lr_cm)

plt.figure(figsize=(6, 4))
sns.heatmap(lr_cm, annot=True, cmap='Spectral', fmt='g')
plt.xlabel('Predicted labels')
plt.ylabel('Actual labels')
plt.title('Confusion Matrix of Logistic Regression')
plt.show()

print("The Classification Report of Logistic Regression")
print(classification_report(y_test, y_pred))

"""### Decision Tree"""

dt_cm = confusion_matrix(y_test, y_pred)
print("Confusion Matrix of Decision Tree Classifier:")
print(dt_cm)

plt.figure(figsize=(6, 4))
sns.heatmap(dt_cm, annot=True, cmap='Spectral', fmt='g')
plt.xlabel('Predicted labels')
plt.ylabel('Actual labels')
plt.title('Confusion Matrix of Decision Tree Classifier')
plt.show()

print("The Classification Report of Decision Tree Classifier")
print(classification_report(y_test, y_pred, zero_division=1))

"""### Random Forest"""

rf_cm = confusion_matrix(y_test, y_pred)
print("Confusion Matrix of Random Forest Classifier:")
print(rf_cm)

plt.figure(figsize=(6, 4))
sns.heatmap(rf_cm, annot=True, cmap='Spectral', fmt='g')
plt.xlabel('Predicted labels')
plt.ylabel('Actual labels')
plt.title('Confusion Matrix of Random Forest Classifier')
plt.show()

print("The Classification Report of Random Forest Classifier")
print(classification_report(y_test, y_pred))

"""## Deployment

save model logistic regression
"""

joblib.dump(clf_lr_grid, 'logistic_regression_model.joblib')

# Load model di enviroment
grid = joblib.load("logistic_regression_model.joblib")

# Simpan ulang hanya model terbaik
joblib.dump(grid.best_estimator_, "logistic_regression_best_model.joblib")

"""uji model"""

import joblib

# Simpan model dan scaler
joblib.dump(lr_cm, 'lr_dropout_model.pkl')

# Simpan nama kolom yang dipakai dalam model
feature_order = student_df.drop(columns=['Status']).columns.tolist()
joblib.dump(feature_order, "model/feature_order.joblib")

feature_order = student_df.drop(columns=['Status']).columns.tolist()
joblib.dump(feature_order, 'feature_names.pkl')

scaler.fit(student_df[feature_names])
joblib.dump(scaler, 'scaler.pkl')

import pandas as pd
import numpy as np
import joblib
import os

# Load model dan dependensi
model = joblib.load("logistic_regression_best_model.joblib")
feature_order = joblib.load("model/feature_order.joblib")
label_encoder = joblib.load("model/encoder_target.joblib")

# Contoh data baru (ganti sesuai input)
data_baru = {
    'Gender': ['Yes'],
    'Debtor': ['No'],
    'Scholarship_holder': ['No'],
    'International': ['No'],
    'Application_mode': [1],
    'Application_order': [1],
    'Admission_grade': [140.0],
    'Previous_qualification': [1],
    'Previous_qualification_grade': [120.0],
    'Nacionality': [1],
    'Mother_qualification': [1],
    'Father_qualification': [1],
    'Mother_occupation': [1],
    'Father_occupation': [1],
    'Educational_special_needs': ['No'],
    'Displaced': ['No'],
    'Curricular_units_1st_sem_approved': [5],
    'Curricular_units_1st_sem_grade': [13.5],
    'Curricular_units_1st_sem_enrolled': [6],
    'Curricular_units_1st_sem_credited': [5],
    'Curricular_units_2nd_sem_approved': [4],
    'Curricular_units_2nd_sem_grade': [14.0],
    'Curricular_units_2nd_sem_enrolled': [5],
    'Curricular_units_2nd_sem_credited': [4],
    'Daytime_evening_attendance': ['Yes'],
    'Tuition_fees_up_to_date': ['Yes'],
}

df_baru = pd.DataFrame(data_baru)

# Pastikan urutan kolom sama
df_baru = df_baru[feature_order]

# Cek nilai string yang mencurigakan
print("Nilai unik sebelum encoding:")
for col in df_baru.columns:
    if df_baru[col].dtype == 'object':
        print(f"{col}: {df_baru[col].unique()}")

# Encode kategori
for col in df_baru.select_dtypes(include='object').columns:
    encoder_path = f"model/encoder_{col}.joblib"
    if os.path.exists(encoder_path):
        le = joblib.load(encoder_path)
        df_baru[col] = le.transform(df_baru[col])
    else:
        print(f"[SKIP] Encoder tidak ditemukan untuk kolom: {col}")


# Scale numerik
for col in df_baru.columns:
    scaler_path = f"model/scaler_{col}.joblib"
    if os.path.exists(scaler_path):
        scaler = joblib.load(scaler_path)
        df_baru[col] = scaler.transform(df_baru[[col]])

# Prediksi
prediksi = model.predict(df_baru)
label_prediksi = label_encoder.inverse_transform(prediksi)

print("Prediksi:", label_prediksi[0])